# CSV Processor Service - Procesamiento de Archivos CSV

El servicio **csv-processor** es responsable del procesamiento asÃ­ncrono de archivos CSV. Procesa archivos CSV grandes de forma eficiente usando streaming, validaciÃ³n a nivel de fila, e inserciÃ³n por lotes en la base de datos.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [Arquitectura](#arquitectura)
- [Funcionalidades](#funcionalidades)
- [Comandos TCP](#comandos-tcp)
- [Formato de CSV](#formato-de-csv)
- [Pipeline de Procesamiento](#pipeline-de-procesamiento)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [Base de Datos](#base-de-datos)

## ğŸ¯ DescripciÃ³n

El servicio `csv-processor` es un microservicio NestJS que:

- Escucha en el puerto **3003** (configurable vÃ­a `PORT_CSV_PROCESSOR`)
- Se comunica vÃ­a **TCP** con el API Gateway
- Procesa archivos CSV de forma asÃ­ncrona usando **streaming**
- Valida filas a nivel individual y maneja errores de forma elegante
- Inserta datos en la base de datos por **lotes** (1,000 registros por operaciÃ³n)
- Sigue una arquitectura **Clean Architecture** con separaciÃ³n de capas

## ğŸ—ï¸ Arquitectura

### Clean Architecture

El servicio estÃ¡ organizado siguiendo los principios de Clean Architecture:

```
apps/csv-processor/src/
â”œâ”€â”€ domain/                    # Capa de Dominio
â”‚   â”œâ”€â”€ entities/              # Entidades de negocio
â”‚   â”‚   â””â”€â”€ review.entity.ts
â”‚   â””â”€â”€ repositories/          # Interfaces de repositorios
â”‚       â””â”€â”€ review.repository.interface.ts
â”œâ”€â”€ application/               # Capa de AplicaciÃ³n
â”‚   â””â”€â”€ use-cases/
â”‚       â””â”€â”€ process-csv.use-case.ts
â”œâ”€â”€ infrastructure/            # Capa de Infraestructura
â”‚   â”œâ”€â”€ persistence/           # ImplementaciÃ³n de repositorio con Prisma
â”‚   â”‚   â””â”€â”€ prisma/
â”‚   â”‚       â””â”€â”€ prisma-review.repository.ts
â”‚   â””â”€â”€ http/                  # Controladores TCP
â”‚       â””â”€â”€ controllers/
â”‚           â””â”€â”€ csv.controller.ts
â”œâ”€â”€ app/                       # Capa de PresentaciÃ³n
â”‚   â”œâ”€â”€ app.module.ts          # MÃ³dulo principal
â”‚   â””â”€â”€ app.service.ts
â”œâ”€â”€ config/                    # ConfiguraciÃ³n
â”‚   â””â”€â”€ envs.ts
â””â”€â”€ main.ts                    # Punto de entrada
```

## âœ¨ Funcionalidades

### 1. Procesamiento de CSV

Procesa archivos CSV y guarda los datos en la base de datos.

**Comando TCP**: `process_csv`

**Payload**:
```typescript
{
  filePath: string;  // Ruta absoluta al archivo CSV
}
```

**Proceso**:
1. Valida que el archivo exista
2. Lee el archivo usando streaming (no carga todo en memoria)
3. Parsea cada fila del CSV
4. Valida cada fila (rating, title, content)
5. Agrupa filas vÃ¡lidas en lotes de 1,000
6. Inserta lotes en la base de datos
7. Registra filas invÃ¡lidas en logs
8. Retorna el nÃºmero total de registros procesados

**Respuesta**:
```typescript
{
  message: string;   // "CSV processed successfully"
  count: number;     // NÃºmero total de registros procesados
}
```

**Errores**:
- `Error`: Si el archivo no existe o hay un error en el procesamiento

## ğŸ”Œ Comandos TCP

El servicio expone el siguiente comando TCP que puede ser invocado desde el API Gateway:

| Comando | DescripciÃ³n | Payload |
|---------|-------------|---------|
| `process_csv` | Procesar archivo CSV | `{ filePath: string }` |

### Flujo Completo desde API Gateway

1. **Cliente sube archivo** al API Gateway vÃ­a HTTP POST `/api/csv/process`
2. **API Gateway guarda archivo** en `./tmp/uploads/` con nombre aleatorio
3. **API Gateway envÃ­a comando TCP** `process_csv` con la ruta absoluta del archivo
4. **CSV Processor procesa** el archivo y guarda datos en la base de datos
5. **CSV Processor retorna** resultado al API Gateway
6. **API Gateway retorna** respuesta HTTP al cliente

## ğŸ“„ Formato de CSV

El servicio espera archivos CSV con el siguiente formato:

### Estructura

```csv
rating,title,content
5,Great movie,This is an excellent film with great acting.
4,Good film,Really enjoyed watching this movie.
3,Average,It was okay, nothing special.
```

### Columnas

1. **rating** (nÃºmero): CalificaciÃ³n del 1 al 5
2. **title** (string): TÃ­tulo de la reseÃ±a
3. **content** (string): Contenido de la reseÃ±a

### ValidaciÃ³n

- **rating**: Debe ser un nÃºmero vÃ¡lido (1-5)
- **title**: Debe ser una cadena de texto no vacÃ­a
- **content**: Debe ser una cadena de texto no vacÃ­a

**Filas invÃ¡lidas**:
- Se registran en logs con nivel `warn`
- Se omiten del procesamiento
- No detienen el procesamiento del resto del archivo

## ğŸ”„ Pipeline de Procesamiento

```mermaid
graph LR
    subgraph "Cliente"
        C[Cliente]
    end
    
    subgraph "API Gateway"
        AG[Gateway Controller]
        FS[File Storage<br/>./tmp/uploads/]
    end
    
    subgraph "CSV Processor"
        CC[CSV Controller]
        PCU[ProcessCsvUseCase]
        Stream[CSV Stream Parser]
        Valid[Row Validator]
        Batch[Batch Collector<br/>1000 rows]
        Repo[Review Repository]
    end
    
    subgraph "Database"
        DB[(PostgreSQL<br/>test_micro)]
    end
    
    C -->|1. POST /api/csv/process<br/>multipart/form-data| AG
    AG -->|2. Save File| FS
    AG -->|3. TCP {cmd: 'process_csv',<br/>filePath}| CC
    CC -->|4. Execute| PCU
    PCU -->|5. Read File| Stream
    Stream -->|6. Parse Row| Valid
    Valid -->|7. Valid Row?| Batch
    Batch -->|8. Batch Full?<br/>1000 rows| Repo
    Repo -->|9. createMany| DB
    DB -->|10. Success| Repo
    Repo -->|11. Response| PCU
    PCU -->|12. Response| CC
    CC -->|13. TCP Response| AG
    AG -->|14. HTTP Response| C
    
    style AG fill:#4a90e2,stroke:#2c5aa0,color:#fff
    style PCU fill:#ffa500,stroke:#cc8400,color:#fff
    style DB fill:#50c878,stroke:#2d7a4a,color:#fff
```

### 1. RecepciÃ³n del Archivo

El API Gateway recibe el archivo CSV vÃ­a multipart/form-data y lo guarda en `./tmp/uploads/`:

```typescript
// En API Gateway
@Post('process')
@UseInterceptors(FileInterceptor('file', {
  storage: diskStorage({
    destination: './tmp/uploads',
    filename: (req, file, cb) => {
      const randomName = Array(32).fill(null)
        .map(() => (Math.round(Math.random() * 16)).toString(16))
        .join('');
      return cb(null, `${randomName}${extname(file.originalname)}`);
    }
  })
}))
async processCsv(@UploadedFile() file: Express.Multer.File) {
  const absolutePath = fs.realpathSync(file.path);
  return this.client.send({ cmd: 'process_csv' }, { filePath: absolutePath });
}
```

### 2. Streaming del Archivo

El servicio lee el archivo usando streaming para no cargar todo en memoria:

```typescript
const stream = fs.createReadStream(csvFilePath)
  .pipe(csv.parse({ headers: false }));
```

### 3. Procesamiento por Lotes

```mermaid
flowchart TD
    Start[Iniciar Procesamiento] --> Read[Leer Fila CSV]
    Read --> Validate{Validar Fila}
    Validate -->|VÃ¡lida| Add[Agregar a Batch]
    Validate -->|InvÃ¡lida| Log[Log Warning]
    Log --> Read
    Add --> Check{Batch >= 1000?}
    Check -->|SÃ­| Insert[Insertar Batch en DB]
    Check -->|No| Read
    Insert --> Clear[Limpiar Batch]
    Clear --> Read
    Read --> End{Fin de Archivo?}
    End -->|No| Validate
    End -->|SÃ­| Final{Â¿Batch Restante?}
    Final -->|SÃ­| InsertFinal[Insertar Batch Final]
    Final -->|No| Complete[Procesamiento Completo]
    InsertFinal --> Complete
    
    style Start fill:#4a90e2,stroke:#2c5aa0,color:#fff
    style Insert fill:#50c878,stroke:#2d7a4a,color:#fff
    style Complete fill:#50c878,stroke:#2d7a4a,color:#fff
    style Log fill:#ffa500,stroke:#cc8400,color:#fff
```

Las filas se agrupan en lotes de 1,000 registros:

```typescript
const BATCH_SIZE = 1000;
let batch: Omit<Review, 'id'>[] = [];

for await (const row of stream) {
  // Validar y agregar a batch
  if (isValid(row)) {
    batch.push(transformRow(row));
  }
  
  // Insertar cuando el batch estÃ¡ lleno
  if (batch.length >= BATCH_SIZE) {
    await this.reviewRepository.createMany(batch);
    batch = [];
  }
}

// Insertar registros restantes
if (batch.length > 0) {
  await this.reviewRepository.createMany(batch);
}
```

### 4. ValidaciÃ³n de Filas

Cada fila se valida antes de agregarse al batch:

```typescript
const rating = parseInt(row[0], 10);
const title = row[1];
const content = row[2];

if (!isNaN(rating) && typeof title === 'string' && typeof content === 'string') {
  batch.push({ rating, title, content });
} else {
  this.logger.warn(`Skipping invalid row: ${row}`);
}
```

### 5. InserciÃ³n en Base de Datos

Los lotes se insertan usando `createMany` de Prisma para eficiencia:

```typescript
await this.prisma.review.createMany({
  data: reviews,
});
```

## ğŸ“Š Modelo de Datos

### Entidad Review

```typescript
export class Review {
  id: number;        // ID auto-generado
  rating: number;    // CalificaciÃ³n (1-5)
  title: string;     // TÃ­tulo de la reseÃ±a
  content: string;   // Contenido de la reseÃ±a
}
```

### Esquema de Base de Datos

El servicio utiliza la base de datos `test_micro` con el siguiente esquema (definido en `libs/prisma-client/prisma/schema.prisma`):

```prisma
model Review {
  id      Int    @id @default(autoincrement())
  rating  Int
  title   String
  content String

  @@map("reviews")
}
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

Agrega al archivo `.env` en la raÃ­z del proyecto:

```env
# Puerto del servicio
PORT_CSV_PROCESSOR=3003

# Base de Datos
DATABASE_URL=postgresql://postgres:root@localhost:5432/test_micro?schema=public

# OpenTelemetry
OTEL_SERVICE_NAME=csv-processor
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
```

### ConfiguraciÃ³n de TamaÃ±o de Lote

El tamaÃ±o del lote se puede ajustar en `apps/csv-processor/src/application/use-cases/process-csv.use-case.ts`:

```typescript
const BATCH_SIZE = 1000;  // Ajusta segÃºn tus necesidades
```

**Consideraciones**:
- Lotes mÃ¡s grandes = menos operaciones de base de datos pero mÃ¡s uso de memoria
- Lotes mÃ¡s pequeÃ±os = mÃ¡s operaciones pero menos uso de memoria
- 1,000 es un buen balance para la mayorÃ­a de casos

## ğŸ’¾ Base de Datos

### Migraciones

Para aplicar migraciones:

```bash
pnpm prisma:migrate:dev
```

Para regenerar el cliente Prisma:

```bash
pnpm prisma:generate
```

## ğŸš€ EjecuciÃ³n

### Desarrollo

```bash
# Desde la raÃ­z del proyecto
pnpm start:csv-processor

# O usando Nx directamente
nx serve csv-processor
```

### ProducciÃ³n

```bash
# Build
pnpm build:csv-processor

# Ejecutar build
node dist/apps/csv-processor/main.js
```

## ğŸ§ª Testing

### Tests E2E

```bash
pnpm test:csv-processor:e2e
```

**Requisitos**:
- Base de datos configurada y migrada
- API Gateway corriendo (para tests de integraciÃ³n)
- Archivo CSV de prueba disponible

### Ejemplo de Uso

```bash
# Subir archivo CSV
curl -X POST http://localhost:3000/api/csv/process \
  -F "file=@mi-archivo.csv"
```

## ğŸ“Š Observabilidad

El servicio estÃ¡ instrumentado con OpenTelemetry:

- **Traces**: Todas las operaciones de procesamiento se rastrean
- **Metrics**: MÃ©tricas de rendimiento (tiempo de procesamiento, nÃºmero de registros, etc.)
- **Logs**: Logs estructurados con Winston
  - `info`: Inicio y fin de procesamiento, lotes guardados
  - `warn`: Filas invÃ¡lidas omitidas
  - `error`: Errores durante el procesamiento

**Ver en SigNoz**: http://localhost:8080

### Logs de Errores

Los errores tambiÃ©n se registran en un archivo local:
- **UbicaciÃ³n**: `csv-processor-error.log` (en la raÃ­z del proyecto)
- **Formato**: JSON con detalles del error

## ğŸ” Manejo de Errores

### Errores Recuperables

- **Filas invÃ¡lidas**: Se registran y se omiten, el procesamiento continÃºa
- **Errores de validaciÃ³n**: Se registran en logs, no detienen el procesamiento

### Errores No Recuperables

- **Archivo no encontrado**: Se lanza error y se detiene el procesamiento
- **Errores de base de datos**: Se lanza error y se detiene el procesamiento

### DegradaciÃ³n Elegante

El servicio estÃ¡ diseÃ±ado para:
- Continuar procesando aunque algunas filas sean invÃ¡lidas
- Registrar todos los errores para anÃ¡lisis posterior
- Retornar el nÃºmero de registros procesados exitosamente

## ğŸ“š Casos de Uso

### ProcessCsvUseCase

El caso de uso principal encapsula toda la lÃ³gica de procesamiento:

1. **ValidaciÃ³n de archivo**: Verifica que el archivo exista
2. **Streaming**: Lee el archivo sin cargar todo en memoria
3. **Parsing**: Parsea cada fila del CSV
4. **ValidaciÃ³n**: Valida cada fila
5. **AgrupaciÃ³n**: Agrupa filas vÃ¡lidas en lotes
6. **Persistencia**: Inserta lotes en la base de datos
7. **Logging**: Registra progreso y errores

### Repositorio

El repositorio abstrae el acceso a datos:

**Interfaz** (`domain/repositories/review.repository.interface.ts`):
```typescript
export interface IReviewRepository {
  createMany(reviews: Omit<Review, 'id'>[]): Promise<void>;
}
```

**ImplementaciÃ³n** (`infrastructure/persistence/prisma/prisma-review.repository.ts`):
- Implementa la interfaz usando Prisma
- Utiliza `createMany` para inserciÃ³n eficiente por lotes

## ğŸ¯ Mejores PrÃ¡cticas

### Para Archivos Grandes

1. **Usar streaming**: El servicio ya usa streaming, no carga todo en memoria
2. **Procesar por lotes**: Ya implementado con tamaÃ±o configurable
3. **Manejar errores**: Filas invÃ¡lidas no detienen el procesamiento
4. **Monitorear**: Usar observabilidad para monitorear el progreso

### Optimizaciones

- **TamaÃ±o de lote**: Ajusta `BATCH_SIZE` segÃºn el tamaÃ±o de tus registros
- **ValidaciÃ³n**: La validaciÃ³n es rÃ¡pida, pero puedes optimizarla si es necesario
- **Logging**: Los logs son importantes para debugging, pero pueden afectar el rendimiento

## ğŸ“š Referencias

- [README Principal](../../README.md)
- [DocumentaciÃ³n de NestJS Microservices](https://docs.nestjs.com/microservices/basics)
- [DocumentaciÃ³n de fast-csv](https://c2fo.io/fast-csv/)
- [DeepWiki - CSV Processor Service](https://deepwiki.com/bleidertcs/nx-micro/10-csv-processor-service)

